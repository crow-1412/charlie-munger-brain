"""
ä¹¦ç±çŸ¥è¯†æå–æ¨¡å—
ä»ã€Šç©·æŸ¥ç†å®å…¸ã€‹ä¸­è‡ªåŠ¨æå–å®ä½“å’Œå…³ç³»
"""

import re
import json
from pathlib import Path
from typing import List, Dict, Tuple, Set
from collections import Counter
from dataclasses import dataclass

from rich.console import Console
from rich.progress import track

from .schema import Entity, Relationship, EntityType, RelationType

console = Console()


# ===== é¢„å®šä¹‰çš„é‡è¦æ¦‚å¿µè¯å…¸ =====
# è¿™äº›æ˜¯èŠ’æ ¼æ€æƒ³ä¸­çš„æ ¸å¿ƒæ¦‚å¿µï¼Œç”¨äºè¾…åŠ©è¯†åˆ«

MENTAL_MODELS = {
    "å¤šå…ƒæ€ç»´æ¨¡å‹", "é€†å‘æ€ç»´", "é€†å‘æ€è€ƒ", "å¤åˆ©", "å¤åˆ©æ•ˆåº”", "èƒ½åŠ›åœˆ",
    "å®‰å…¨è¾¹é™…", "æŠ¤åŸæ²³", "æœºä¼šæˆæœ¬", "æ¦‚ç‡æ€ç»´", "è´¹é©¬-å¸•æ–¯å¡ç³»ç»Ÿ",
    "lollapaloozaæ•ˆåº”", "Lollapalooza", "æ ¼æ …æ€ç»´", "å¤šå­¦ç§‘æ€ç»´",
    "æ£€æŸ¥æ¸…å•", "åŒè½¨åˆ†æ", "åè¿‡æ¥æƒ³", "è·¨å­¦ç§‘"
}

COGNITIVE_BIASES = {
    "å¥–åŠ±å’Œæƒ©ç½šè¶…çº§ååº”å€¾å‘", "æ¿€åŠ±æœºåˆ¶", "å–œæ¬¢/çƒ­çˆ±å€¾å‘", "è®¨åŒ/æ†æ¨å€¾å‘",
    "é¿å…æ€€ç–‘å€¾å‘", "é¿å…ä¸ä¸€è‡´æ€§å€¾å‘", "å¥½å¥‡å¿ƒå€¾å‘", "åº·å¾·å¼å…¬å¹³å€¾å‘",
    "è‰³ç¾¡/å¦’å¿Œå€¾å‘", "å›é¦ˆå€¾å‘", "ç®€å•è”æƒ³", "å¿ƒç†å¦è®¤", "è‡ªè§†è¿‡é«˜",
    "è¿‡åº¦ä¹è§‚", "è¢«å‰¥å¤ºè¶…çº§ååº”", "ç¤¾ä¼šè®¤åŒ", "ä»ä¼—", "å¯¹æ¯”é”™è¯¯ååº”",
    "å‹åŠ›å½±å“", "é”™è¯¯è¡¡é‡æ˜“å¾—æ€§", "ä¸ç”¨å°±å¿˜", "åŒ–å­¦ç‰©è´¨é”™è¯¯å½±å“",
    "è¡°è€é”™è¯¯å½±å“", "æƒå¨é”™è¯¯å½±å“", "åºŸè¯å€¾å‘", "é‡è§†ç†ç”±å€¾å‘",
    "é“é”¤äººç»¼åˆå¾", "é“é”¤äºº", "è¯¯åˆ¤å¿ƒç†å­¦", "è®¤çŸ¥åè¯¯"
}

IMPORTANT_PEOPLE = {
    "æŸ¥ç†Â·èŠ’æ ¼", "èŠ’æ ¼", "æ²ƒä¼¦Â·å·´è²ç‰¹", "å·´è²ç‰¹", "æœ¬æ°æ˜Â·å¯Œå…°å…‹æ—",
    "å¯Œå…°å…‹æ—", "æœ¬æ°æ˜Â·æ ¼é›·å„å§†", "æ ¼é›·å„å§†", "è´¹é›ª", "è²åˆ©æ™®Â·è´¹é›ª",
    "äºšå½“Â·æ–¯å¯†", "è¾¾å°”æ–‡", "çˆ±å› æ–¯å¦", "ç‰›é¡¿", "å‡¯æ©æ–¯", "è‹æ ¼æ‹‰åº•",
    "æŸæ‹‰å›¾", "äºšé‡Œå£«å¤šå¾·", "è¥¿å¡ç½—", "å¡å†…å¡", "é©¬å…‹Â·åæ¸©",
    "æå½•", "å½¼å¾—Â·è€ƒå¤«æ›¼"
}

COMPANIES = {
    "ä¼¯å…‹å¸Œå°”Â·å“ˆæ’’éŸ¦", "ä¼¯å…‹å¸Œå°”", "å¯å£å¯ä¹", "å–œè¯—ç³–æœ", "GEICO",
    "åç››é¡¿é‚®æŠ¥", "ç¾å›½è¿é€š", "æ‰€ç½—é—¨", "é€šç”¨å†ä¿é™©", "ä¸­ç¾èƒ½æº",
    "å¥½å¸‚å¤š", "Costco", "æ¯æ—¥æœŸåˆŠ", "å¨æ–¯ç§‘é‡‘è", "è“ç­¹å°èŠ±"
}

DISCIPLINES = {
    "ç‰©ç†å­¦", "æ•°å­¦", "ç”Ÿç‰©å­¦", "å¿ƒç†å­¦", "ç»æµå­¦", "ä¼šè®¡å­¦",
    "å·¥ç¨‹å­¦", "ç»Ÿè®¡å­¦", "åŒ–å­¦", "å†å²å­¦", "å“²å­¦", "æ³•å­¦"
}


class BookKnowledgeExtractor:
    """ä»ä¹¦ç±ä¸­æå–çŸ¥è¯†"""
    
    def __init__(self, llm=None):
        self.llm = llm
        self.entities: Dict[str, Entity] = {}
        self.relationships: List[Relationship] = []
    
    def extract_from_file(self, file_path: str) -> Tuple[Dict[str, Entity], List[Relationship]]:
        """ä»æ–‡ä»¶æå–çŸ¥è¯†"""
        with open(file_path, 'r', encoding='utf-8') as f:
            text = f.read()
        return self.extract_from_text(text)
    
    def extract_from_text(self, text: str) -> Tuple[Dict[str, Entity], List[Relationship]]:
        """ä»æ–‡æœ¬æå–çŸ¥è¯†"""
        console.print("[bold cyan]ğŸ“š å¼€å§‹ä»ä¹¦ç±ä¸­æå–çŸ¥è¯†...[/bold cyan]")
        
        # 1. åˆ†ç« èŠ‚
        chapters = self._split_chapters(text)
        console.print(f"ğŸ“– å…± {len(chapters)} ä¸ªç« èŠ‚")
        
        # 2. æå–å®ä½“
        console.print("\n[yellow]ğŸ” æå–å®ä½“...[/yellow]")
        self._extract_entities(chapters)
        console.print(f"âœ… æ‰¾åˆ° {len(self.entities)} ä¸ªå®ä½“")
        
        # 3. æå–å…³ç³»
        console.print("\n[yellow]ğŸ”— æå–å…³ç³»...[/yellow]")
        self._extract_relationships(chapters)
        console.print(f"âœ… æ‰¾åˆ° {len(self.relationships)} ä¸ªå…³ç³»")
        
        return self.entities, self.relationships
    
    def _split_chapters(self, text: str) -> List[Dict]:
        """åˆ†å‰²ç« èŠ‚"""
        chapters = []
        # æŒ‰ === æ ‡è®°åˆ†å‰²
        parts = re.split(r'\n===\s*(.*?)\s*===\n', text)
        
        for i in range(1, len(parts), 2):
            if i + 1 < len(parts):
                title = parts[i]
                content = parts[i + 1]
                if len(content.strip()) > 100:  # è¿‡æ»¤å¤ªçŸ­çš„ç« èŠ‚
                    chapters.append({
                        "title": title,
                        "content": content,
                        "index": len(chapters)
                    })
        
        return chapters
    
    def _extract_entities(self, chapters: List[Dict]):
        """æå–å®ä½“"""
        all_text = ' '.join(c['content'] for c in chapters)
        
        # 1. æå–æ€ç»´æ¨¡å‹
        for model in MENTAL_MODELS:
            if model in all_text:
                count = all_text.count(model)
                self._add_entity(
                    model, EntityType.MENTAL_MODEL,
                    f"èŠ’æ ¼çš„æ ¸å¿ƒæ€ç»´æ¨¡å‹ï¼Œä¹¦ä¸­å‡ºç° {count} æ¬¡",
                    importance=count
                )
        
        # 2. æå–è®¤çŸ¥åè¯¯
        for bias in COGNITIVE_BIASES:
            if bias in all_text:
                count = all_text.count(bias)
                self._add_entity(
                    bias, EntityType.COGNITIVE_BIAS,
                    f"äººç±»è¯¯åˆ¤å¿ƒç†å­¦ä¸­çš„è®¤çŸ¥åè¯¯ï¼Œä¹¦ä¸­å‡ºç° {count} æ¬¡",
                    importance=count
                )
        
        # 3. æå–äººç‰©
        for person in IMPORTANT_PEOPLE:
            if person in all_text:
                count = all_text.count(person)
                if count >= 3:  # è‡³å°‘å‡ºç°3æ¬¡
                    self._add_entity(
                        person, EntityType.PERSON,
                        f"ä¹¦ä¸­é‡è¦äººç‰©ï¼Œå‡ºç° {count} æ¬¡",
                        importance=count
                    )
        
        # 4. æå–å…¬å¸
        for company in COMPANIES:
            if company in all_text:
                count = all_text.count(company)
                if count >= 2:
                    self._add_entity(
                        company, EntityType.COMPANY,
                        f"ä¹¦ä¸­æåˆ°çš„å…¬å¸ï¼Œå‡ºç° {count} æ¬¡",
                        importance=count
                    )
        
        # 5. æå–å­¦ç§‘
        for discipline in DISCIPLINES:
            if discipline in all_text:
                count = all_text.count(discipline)
                if count >= 3:
                    self._add_entity(
                        discipline, EntityType.DISCIPLINE,
                        f"è·¨å­¦ç§‘æ€ç»´æ¶‰åŠçš„å­¦ç§‘ï¼Œå‡ºç° {count} æ¬¡",
                        importance=count
                    )
        
        # 6. ä½¿ç”¨æ­£åˆ™æå–æ›´å¤šæ¦‚å¿µ
        self._extract_concepts_by_pattern(all_text)
        
        # 7. æå–åè¨€/åŸåˆ™
        self._extract_quotes(all_text)
    
    def _extract_concepts_by_pattern(self, text: str):
        """ä½¿ç”¨æ¨¡å¼åŒ¹é…æå–æ¦‚å¿µ"""
        # åŒ¹é…"XXXæ€ç»´"ã€"XXXåŸåˆ™"ã€"XXXæ•ˆåº”"ç­‰
        patterns = [
            (r'["\']([^"\']{2,15}(?:æ€ç»´|åŸåˆ™|æ•ˆåº”|æ³•åˆ™|å®šå¾‹|æ¨¡å‹))["\']', EntityType.MENTAL_MODEL),
            (r'ã€Œ([^ã€]{2,15}(?:æ€ç»´|åŸåˆ™|æ•ˆåº”|æ³•åˆ™|å®šå¾‹|æ¨¡å‹))ã€', EntityType.MENTAL_MODEL),
            (r'([ä¸€-é¾¥]{2,8}(?:æ€ç»´|åŸåˆ™|æ•ˆåº”|æ³•åˆ™|å®šå¾‹|æ¨¡å‹))', EntityType.MENTAL_MODEL),
        ]
        
        for pattern, entity_type in patterns:
            matches = re.findall(pattern, text)
            for match in matches:
                if len(match) <= 15 and match not in self.entities:
                    count = text.count(match)
                    if count >= 2:
                        self._add_entity(
                            match, entity_type,
                            f"ä»æ–‡æœ¬ä¸­æå–çš„æ¦‚å¿µï¼Œå‡ºç° {count} æ¬¡",
                            importance=count
                        )
    
    def _extract_quotes(self, text: str):
        """æå–åè¨€ä½œä¸ºåŸåˆ™"""
        # èŠ’æ ¼çš„è‘—åè¯­å½•æ¨¡å¼
        quote_patterns = [
            r'èŠ’æ ¼è¯´[ï¼š:][""]([^""]{10,50})[""]',
            r'èŠ’æ ¼è®¤ä¸º[ï¼š:ï¼Œ,]([^ã€‚]{10,50})',
            r'[""]([^""]{10,40})[""][ï¼Œ,]â€”â€”èŠ’æ ¼',
        ]
        
        for pattern in quote_patterns:
            matches = re.findall(pattern, text)
            for match in matches[:10]:  # æœ€å¤š10æ¡
                # æ¸…ç†å¹¶æˆªæ–­
                quote = match.strip()[:40]
                if len(quote) > 10:
                    self._add_entity(
                        f"ã€Œ{quote}ã€", EntityType.PRINCIPLE,
                        "èŠ’æ ¼çš„æ™ºæ…§ç®´è¨€",
                        importance=1
                    )
    
    def _add_entity(self, name: str, entity_type: EntityType, description: str, importance: int = 1):
        """æ·»åŠ å®ä½“"""
        # æ ‡å‡†åŒ–åç§°
        name = name.strip()
        if not name or len(name) < 2:
            return
        
        if name not in self.entities:
            self.entities[name] = Entity(
                name=name,
                entity_type=entity_type,
                description=description,
                attributes={"importance": importance}
            )
        else:
            # æ›´æ–°é‡è¦æ€§
            current = self.entities[name].attributes.get("importance", 0)
            self.entities[name].attributes["importance"] = current + importance
    
    def _extract_relationships(self, chapters: List[Dict]):
        """æå–å…³ç³»"""
        all_text = ' '.join(c['content'] for c in chapters)
        entity_names = set(self.entities.keys())
        
        # å…³ç³»æ¨¡å¼
        relation_patterns = [
            # A æå‡º/åˆ›é€  B
            (r'({})(?:æå‡º|åˆ›é€ |å‘æ˜|æå€¡|ä¸»å¼ |å¼ºè°ƒ)(?:äº†)?[çš„]?({})'.format, RelationType.SUPPORTS),
            # A å½±å“ B
            (r'({})(?:å½±å“|å¯å‘|å¡‘é€ )(?:äº†)?({})'.format, RelationType.INFLUENCED_BY),
            # A åº”ç”¨äº B
            (r'({})(?:åº”ç”¨äº|ç”¨äº|é€‚ç”¨äº)({})'.format, RelationType.APPLIES_TO),
            # A æºè‡ª B
            (r'({})(?:æºè‡ª|æ¥è‡ª|å€Ÿé‰´è‡ª)({})'.format, RelationType.DERIVED_FROM),
            # A ä¸ B ç›¸å…³
            (r'({})(?:å’Œ|ä¸|è·Ÿ)({})(?:ç›¸å…³|æœ‰å…³|ç±»ä¼¼)'.format, RelationType.RELATED_TO),
            # A å¯¼è‡´ B
            (r'({})(?:å¯¼è‡´|é€ æˆ|å¼•å‘)(?:äº†)?({})'.format, RelationType.LEADS_TO),
            # A åå¯¹ B
            (r'({})(?:åå¯¹|æ‰¹è¯„|å¦å®š)({})'.format, RelationType.OPPOSES),
        ]
        
        # å…±ç°å…³ç³»ï¼šåœ¨åŒä¸€æ®µè½ä¸­å‡ºç°çš„å®ä½“å¯èƒ½æœ‰å…³è”
        paragraphs = all_text.split('\n\n')
        cooccurrence = Counter()
        
        for para in paragraphs:
            entities_in_para = [e for e in entity_names if e in para]
            # ä¸¤ä¸¤ç»„åˆ
            for i, e1 in enumerate(entities_in_para):
                for e2 in entities_in_para[i+1:]:
                    if e1 != e2:
                        pair = tuple(sorted([e1, e2]))
                        cooccurrence[pair] += 1
        
        # æ·»åŠ å…±ç°æ¬¡æ•°è¾ƒå¤šçš„å…³ç³»
        for (e1, e2), count in cooccurrence.most_common(100):
            if count >= 3:  # è‡³å°‘å…±ç°3æ¬¡
                self._add_relationship(e1, e2, RelationType.RELATED_TO, f"åœ¨ä¹¦ä¸­å…±åŒå‡ºç° {count} æ¬¡")
        
        # æ·»åŠ é¢„å®šä¹‰çš„æ ¸å¿ƒå…³ç³»
        self._add_core_relationships()
    
    def _add_relationship(self, source: str, target: str, rel_type: RelationType, description: str):
        """æ·»åŠ å…³ç³»"""
        if source in self.entities and target in self.entities and source != target:
            # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
            for rel in self.relationships:
                if rel.source == source and rel.target == target:
                    return
            
            self.relationships.append(Relationship(
                source=source,
                target=target,
                relation_type=rel_type,
                description=description
            ))
    
    def _add_core_relationships(self):
        """æ·»åŠ æ ¸å¿ƒå…³ç³»"""
        core_relations = [
            # äººç‰©å…³ç³»
            ("æŸ¥ç†Â·èŠ’æ ¼", "æ²ƒä¼¦Â·å·´è²ç‰¹", RelationType.COLLABORATED_WITH, "é•¿æœŸåˆä½œä¼™ä¼´"),
            ("æŸ¥ç†Â·èŠ’æ ¼", "ä¼¯å…‹å¸Œå°”Â·å“ˆæ’’éŸ¦", RelationType.PART_OF, "å‰¯è‘£äº‹é•¿"),
            ("æŸ¥ç†Â·èŠ’æ ¼", "å¤šå…ƒæ€ç»´æ¨¡å‹", RelationType.SUPPORTS, "æ ¸å¿ƒå€¡å¯¼è€…"),
            ("æŸ¥ç†Â·èŠ’æ ¼", "é€†å‘æ€è€ƒ", RelationType.SUPPORTS, "'åè¿‡æ¥æƒ³'çš„å€¡å¯¼è€…"),
            
            # æ€æƒ³æ¥æº
            ("å¤šå…ƒæ€ç»´æ¨¡å‹", "ç‰©ç†å­¦", RelationType.DERIVED_FROM, "å€Ÿé‰´ç‰©ç†å­¦æ€ç»´"),
            ("å¤šå…ƒæ€ç»´æ¨¡å‹", "å¿ƒç†å­¦", RelationType.DERIVED_FROM, "å€Ÿé‰´å¿ƒç†å­¦æ€ç»´"),
            ("å¤šå…ƒæ€ç»´æ¨¡å‹", "ç»æµå­¦", RelationType.DERIVED_FROM, "å€Ÿé‰´ç»æµå­¦æ€ç»´"),
            ("å¤šå…ƒæ€ç»´æ¨¡å‹", "æ•°å­¦", RelationType.DERIVED_FROM, "å€Ÿé‰´æ•°å­¦æ€ç»´"),
            ("å¤šå…ƒæ€ç»´æ¨¡å‹", "ç”Ÿç‰©å­¦", RelationType.DERIVED_FROM, "å€Ÿé‰´ç”Ÿç‰©å­¦æ€ç»´"),
            
            # æŠ•èµ„ç›¸å…³
            ("å®‰å…¨è¾¹é™…", "èƒ½åŠ›åœˆ", RelationType.RELATED_TO, "æŠ•èµ„æ ¸å¿ƒåŸåˆ™"),
            ("å¤åˆ©", "ä¼¯å…‹å¸Œå°”Â·å“ˆæ’’éŸ¦", RelationType.APPLIES_TO, "å¤åˆ©æ˜¯ä¼¯å…‹å¸Œå°”æˆåŠŸçš„å…³é”®"),
            
            # è®¤çŸ¥åè¯¯
            ("æ¿€åŠ±æœºåˆ¶", "è¯¯åˆ¤å¿ƒç†å­¦", RelationType.PART_OF, "25ç§è¯¯åˆ¤å¿ƒç†ä¹‹ä¸€"),
            ("ç¤¾ä¼šè®¤åŒ", "è¯¯åˆ¤å¿ƒç†å­¦", RelationType.PART_OF, "25ç§è¯¯åˆ¤å¿ƒç†ä¹‹ä¸€"),
            ("é“é”¤äººç»¼åˆå¾", "å¤šå…ƒæ€ç»´æ¨¡å‹", RelationType.OPPOSES, "é“é”¤äººæ˜¯å¤šå…ƒæ€ç»´çš„åé¢"),
            
            # äººç‰©å½±å“
            ("æœ¬æ°æ˜Â·å¯Œå…°å…‹æ—", "æŸ¥ç†Â·èŠ’æ ¼", RelationType.INFLUENCED_BY, "èŠ’æ ¼æ·±å—å¯Œå…°å…‹æ—å½±å“"),
            ("æœ¬æ°æ˜Â·æ ¼é›·å„å§†", "æ²ƒä¼¦Â·å·´è²ç‰¹", RelationType.INFLUENCED_BY, "å·´è²ç‰¹çš„è€å¸ˆ"),
        ]
        
        for source, target, rel_type, desc in core_relations:
            # å¤„ç†åˆ«å
            source = self._normalize_name(source)
            target = self._normalize_name(target)
            self._add_relationship(source, target, rel_type, desc)
    
    def _normalize_name(self, name: str) -> str:
        """æ ‡å‡†åŒ–åç§°ï¼ˆå¤„ç†åˆ«åï¼‰"""
        aliases = {
            "èŠ’æ ¼": "æŸ¥ç†Â·èŠ’æ ¼",
            "å·´è²ç‰¹": "æ²ƒä¼¦Â·å·´è²ç‰¹",
            "å¯Œå…°å…‹æ—": "æœ¬æ°æ˜Â·å¯Œå…°å…‹æ—",
            "æ ¼é›·å„å§†": "æœ¬æ°æ˜Â·æ ¼é›·å„å§†",
            "ä¼¯å…‹å¸Œå°”": "ä¼¯å…‹å¸Œå°”Â·å“ˆæ’’éŸ¦",
        }
        # å¦‚æœåŸååœ¨å®ä½“ä¸­ï¼Œç›´æ¥è¿”å›
        if name in self.entities:
            return name
        # å°è¯•åˆ«å
        if name in aliases and aliases[name] in self.entities:
            return aliases[name]
        # å°è¯•åå‘æŸ¥æ‰¾
        for alias, full_name in aliases.items():
            if name == full_name and alias in self.entities:
                return alias
        return name


def extract_knowledge_from_book(book_path: str) -> Tuple[Dict[str, Entity], List[Relationship]]:
    """ä»ä¹¦ç±æå–çŸ¥è¯†çš„ä¾¿æ·å‡½æ•°"""
    extractor = BookKnowledgeExtractor()
    return extractor.extract_from_file(book_path)

